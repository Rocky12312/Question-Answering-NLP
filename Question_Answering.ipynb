{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question-Answering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYxYXRQHEDQb6mdE5KZcXe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rocky12312/Question-Answering-NLP/blob/master/Question_Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP3nZAKhzDit",
        "colab_type": "code",
        "outputId": "6aff8b2d-19be-4992-c696-d7544d7f23bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "033DZeFxzNrU",
        "colab_type": "code",
        "outputId": "db0d1fb4-daf2-4e0f-e2e4-61124e99c9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "cd /content/drive/My\\ Drive/Tweet_sentiment_extraction/tasks_1-20_v1-2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Tweet_sentiment_extraction/tasks_1-20_v1-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unbBtP1fzpvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RjgIs5iip4H",
        "colab_type": "text"
      },
      "source": [
        "Data file for this notebook we can also find at https://research.fb.com/downloads/babi and then navigating to HITL Dialogue Simulator there is a file names bAbI Tasks Data 1-20 which contains the data used in this notebook and several other useful data\n",
        "\n",
        "And using the below link we can actually download the data automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXXfSHtd0d2Z",
        "colab_type": "code",
        "outputId": "ff4d78fc-a711-43e2-bba8-9f809c51714a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.utils.data_utils import get_file\n",
        "import tarfile\n",
        "#The keras get_file function to just download the data\n",
        "path = get_file(\"babi-tasks-v1-2.tar.gz\",origin = \"https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\")\n",
        "#Tarfile libraray just takes care of extraction so no need to do it manually\n",
        "fl = tarfile.open(path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArStlSS03H3N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting only the relavent data qa1 with 10,000 samples and qa2 with 10,000 samples\n",
        "#Basically this dictionary tell us where the relevan data is\n",
        "challenges = {\"single_supporting_fact_10k\":\"tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt\",\"two_supporting_fact_10k\":\"tasks_1-20_v1-2/en-10k/qa2_two-supporting-fact_{}.txt\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU_jd5KvKpYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = \"single_supporting_fact_10k\"\n",
        "data_fl = challenges[a]\n",
        "stories_train = fl.extractfile(data_fl.format(\"train\"))\n",
        "stories_test = fl.extractfile(data_fl.format(\"test\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-flREu9LkVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3780b82-7040-4031-8e7b-401a9ee89421"
      },
      "source": [
        "type(stories_train)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tarfile.ExFileObject"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoB4W7vOmE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Running this we can see what our data looks like\n",
        "#for line in stories_train:\n",
        "  #print(line)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwjtrE-E4Kal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sent):\n",
        "  #Here we will be returning tokens including punctuations\n",
        "  return [x.strip() for x in re.split(\"(\\W+)?\",sent) if x.strip()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V63DoDReWItn",
        "colab_type": "text"
      },
      "source": [
        "Now our main task wil be is to generate three containers from our data file which will contain the questions, answers and the story on whose basis the answer to question should be given and this below get_stories function does this task for us"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu5OYEwuuzpx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stories(file):\n",
        "  #Here we will be storing the questions,answers and the context in data list\n",
        "  q_a_c_data = []\n",
        "  #Using story list to keep track of the story so far\n",
        "  story = []\n",
        "  printed = False\n",
        "  for line in file:\n",
        "    line = line.decode('utf-8').strip()\n",
        "\n",
        "    #split the line id number number from the rest of the line\n",
        "    lineid,line = line.split(\" \", 1)\n",
        "\n",
        "    #If the value of our line id is one it means that it is start of new story\n",
        "    if int(lineid) == 1:\n",
        "      story = []\n",
        "    #If we encountered a tab somewhere in line it means that the line contain the question and the answer based on the story so far \n",
        "    #and it also contain information like which line is relavent for answer\n",
        "    if \"\\t\" in line:\n",
        "      ques,ans,supporting = line.split('\\t')\n",
        "      ques = tokenize(ques)\n",
        "      #Numbering the lines adding unique tokens in front of each sentence\n",
        "      story_so_far = [[str(i)] + s for i, s in enumerate(story) if s]\n",
        "      #Now as we have the story so far the question and the answer we will append all this data in our data\n",
        "      q_a_c_data.append((story_so_far,ques,ans))\n",
        "      story.append(\"\")\n",
        "    else:\n",
        "      #If we dont have tab in our line what we gonna do is simply append the tokenized line to story list and do this until we get a line\n",
        "      #in which tab is there\n",
        "      story.append(tokenize(line))\n",
        "  return q_a_c_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IceDJTlaHvCK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0318b017-b841-4a86-c680-215be3c36c7f"
      },
      "source": [
        "data_all = get_stories(stories_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqYaTYTyI-ko",
        "colab_type": "text"
      },
      "source": [
        "This is what the data look like after appending the questions answers and the context in a q_a_c_data list\n",
        "\n",
        "There will be a two dimension list for the context sentences(which are tokenized), a tokenized list of the question and a string containing the answer in every story in our data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ8sqwOlPrCv",
        "colab_type": "text"
      },
      "source": [
        "Now we are having our questions,answers and the context on which these question and answer are based"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WA_URhdNQ3ZM",
        "colab_type": "text"
      },
      "source": [
        "Recursively flattening as list and this function is really helpful in getting the vocabulary size from the data as our data contains various levels lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvTPbEFUYaxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def should_flatten(el):\n",
        "  return not isinstance(el,(str,bytes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Ad0tPLnYv8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flatten(l):\n",
        "  for el in l:\n",
        "    if should_flatten(el):\n",
        "      yield from flatten(el)\n",
        "    else:\n",
        "      yield el"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXT5FCZVRGPe",
        "colab_type": "text"
      },
      "source": [
        "THe below function is for vectorizing stories and here we will be vectorizing the data manually without using the tokenizer as our lists are really complicated in structure in this case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_zKUR6UZFnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorizing_stories(data,word2idx,story_maxlen,query_maxlen):\n",
        "  inputs,queries,answers = [],[],[]\n",
        "  for story,query,answer in data:\n",
        "    #Converting the list of words into list of word indexes\n",
        "    #Vectorizing the story\n",
        "    inputs.append([[word2idx[w] for w in s]for s in story])\n",
        "    #Vectorizing the question(query)\n",
        "    queries.append([word2idx[w] for w in query])\n",
        "    #Vectorizing the answer\n",
        "    answers.append([word2idx[answer]])\n",
        "    #We are also returning the list of padded sequence insted of initial length sequence based upon story maxlen and query maxlen\n",
        "  return ([pad_sequences(x,maxlen = story_maxlen) for x in inputs],pad_sequences(queries,maxlen = query_maxlen),np.array(answers))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "329PZ9ZZTw1C",
        "colab_type": "text"
      },
      "source": [
        "As earlier from the data we have seen that the stories in the data have different number of sentences so we also need to the pad the stories in such a way that we have same number of sentences in our stories and our all stories have same shape"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuBAMa9Ra5EU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stack_inputs(inputs,story_maxsents,story_maxlen):\n",
        "  for i,story in enumerate(inputs):\n",
        "    #Here we will be going through all the stories and will pad them such that their shape will bw same as maximum length story\n",
        "    inputs[i] = np.concatenate([story,np.zeros((story_maxsents-story.shape[0],story_maxlen),\"int\")])\n",
        "  return np.stack(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-Nih5gEUti2",
        "colab_type": "text"
      },
      "source": [
        "Now after running all the above function on the data what we will be having is som what good data which have all the stories of same size and all queries of same size "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Dgxm7s3boOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(challenge_type):\n",
        "  #Using the challenge dictionary to get the data either single support or two support\n",
        "  challenge = challenges[challenge_type]\n",
        "  train_stories = get_stories(fl.extractfile(challenge.format(\"train\")))\n",
        "  test_stories = get_stories(fl.extractfile(challenge.format(\"test\")))\n",
        "  #Appending the train and test stories\n",
        "  stories = train_stories+test_stories\n",
        "  #Next we will be needing the maximum story length,maximum sentence length and maximum query length to pad the story and the queries\n",
        "  #Getting the max story word length(iterating over the stories)\n",
        "  story_maxlen = max((len(s) for x,_,_ in stories for s in x))\n",
        "  #Getting the max sentence number from all the stories\n",
        "  story_maxsents = max((len(x) for x,_,_ in stories))\n",
        "  #Getting the maximum query length\n",
        "  query_maxlen = max(len(x) for _,x,_ in stories)\n",
        "  #Getting the vocabulary using faltten function\n",
        "  vocab = sorted(set(flatten(stories)))\n",
        "  #Inserting the <PAD> token in vocabulary\n",
        "  vocab.insert(0,\"<PAD>\")\n",
        "  vocab_size = len(vocab)\n",
        "  word2idx = {c:i for i,c in enumerate(vocab)}\n",
        "  #Vectorizing the inputs(story,query and answers)\n",
        "  input_train,queries_train,answers_train = vectorizing_stories(train_stories,word2idx,story_maxlen,query_maxlen)\n",
        "  input_test,queries_test,answers_test = vectorizing_stories(test_stories,word2idx,story_maxlen,query_maxlen)\n",
        "  #Padding the stories(so that all have same length)\n",
        "  inputs_train = stack_inputs(input_train,story_maxsents,story_maxlen)\n",
        "  inputs_test = stack_inputs(input_test,story_maxsents,story_maxlen)\n",
        "  print(\"inputs_train.shape,inputs_test.shape\",inputs_train.shape,inputs_test.shape)\n",
        "  return train_stories,test_stories,inputs_train,queries_train,answers_train,inputs_test,queries_test,answers_test,story_maxsents,story_maxlen,query_maxlen,vocab,vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4g9XHASfSuH",
        "colab_type": "code",
        "outputId": "7e3ffe68-dc0c-4c10-b7ed-74af68024fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import keras.backend as K\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "train_stories,test_stories,inputs_train,queries_train,answers_train,inputs_test,queries_test,answers_test,story_maxsents,story_maxlen,query_maxlen,vocab,vocab_size = get_data(\"single_supporting_fact_10k\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "inputs_train.shape,inputs_test.shape (10000, 10, 8) (1000, 10, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwhmxbB-YmQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "acbb7c15-a295-4e45-8f4b-caf349c4d93d"
      },
      "source": [
        "#This is what our data looked like\n",
        "train_stories[0:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([['0', 'Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
              "   ['1', 'John', 'went', 'to', 'the', 'hallway', '.']],\n",
              "  ['Where', 'is', 'Mary', '?'],\n",
              "  'bathroom'),\n",
              " ([['0', 'Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
              "   ['1', 'John', 'went', 'to', 'the', 'hallway', '.'],\n",
              "   ['3', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
              "   ['4', 'Sandra', 'moved', 'to', 'the', 'garden', '.']],\n",
              "  ['Where', 'is', 'Daniel', '?'],\n",
              "  'hallway'),\n",
              " ([['0', 'Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
              "   ['1', 'John', 'went', 'to', 'the', 'hallway', '.'],\n",
              "   ['3', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
              "   ['4', 'Sandra', 'moved', 'to', 'the', 'garden', '.'],\n",
              "   ['6', 'John', 'moved', 'to', 'the', 'office', '.'],\n",
              "   ['7', 'Sandra', 'journeyed', 'to', 'the', 'bathroom', '.']],\n",
              "  ['Where', 'is', 'Daniel', '?'],\n",
              "  'hallway'),\n",
              " ([['0', 'Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
              "   ['1', 'John', 'went', 'to', 'the', 'hallway', '.'],\n",
              "   ['3', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
              "   ['4', 'Sandra', 'moved', 'to', 'the', 'garden', '.'],\n",
              "   ['6', 'John', 'moved', 'to', 'the', 'office', '.'],\n",
              "   ['7', 'Sandra', 'journeyed', 'to', 'the', 'bathroom', '.'],\n",
              "   ['9', 'Mary', 'moved', 'to', 'the', 'hallway', '.'],\n",
              "   ['10', 'Daniel', 'travelled', 'to', 'the', 'office', '.']],\n",
              "  ['Where', 'is', 'Daniel', '?'],\n",
              "  'office'),\n",
              " ([['0', 'Mary', 'moved', 'to', 'the', 'bathroom', '.'],\n",
              "   ['1', 'John', 'went', 'to', 'the', 'hallway', '.'],\n",
              "   ['3', 'Daniel', 'went', 'back', 'to', 'the', 'hallway', '.'],\n",
              "   ['4', 'Sandra', 'moved', 'to', 'the', 'garden', '.'],\n",
              "   ['6', 'John', 'moved', 'to', 'the', 'office', '.'],\n",
              "   ['7', 'Sandra', 'journeyed', 'to', 'the', 'bathroom', '.'],\n",
              "   ['9', 'Mary', 'moved', 'to', 'the', 'hallway', '.'],\n",
              "   ['10', 'Daniel', 'travelled', 'to', 'the', 'office', '.'],\n",
              "   ['12', 'John', 'went', 'back', 'to', 'the', 'garden', '.'],\n",
              "   ['13', 'John', 'moved', 'to', 'the', 'bedroom', '.']],\n",
              "  ['Where', 'is', 'Sandra', '?'],\n",
              "  'bathroom')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF_UJHT9ZQZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        },
        "outputId": "148167c3-e06d-463c-cbd4-1b869de758f9"
      },
      "source": [
        "#This is what our stories look like after id imputation and padding etc\n",
        "inputs_train[0:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0,  2, 15, 26, 29, 28, 19,  1],\n",
              "        [ 0,  3, 14, 31, 29, 28, 22,  1],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "\n",
              "       [[ 0,  2, 15, 26, 29, 28, 19,  1],\n",
              "        [ 0,  3, 14, 31, 29, 28, 22,  1],\n",
              "        [ 7, 13, 31, 18, 29, 28, 22,  1],\n",
              "        [ 0,  8, 16, 26, 29, 28, 21,  1],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "\n",
              "       [[ 0,  2, 15, 26, 29, 28, 19,  1],\n",
              "        [ 0,  3, 14, 31, 29, 28, 22,  1],\n",
              "        [ 7, 13, 31, 18, 29, 28, 22,  1],\n",
              "        [ 0,  8, 16, 26, 29, 28, 21,  1],\n",
              "        [ 0,  9, 14, 26, 29, 28, 27,  1],\n",
              "        [ 0, 10, 16, 24, 29, 28, 19,  1],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "\n",
              "       [[ 0,  2, 15, 26, 29, 28, 19,  1],\n",
              "        [ 0,  3, 14, 31, 29, 28, 22,  1],\n",
              "        [ 7, 13, 31, 18, 29, 28, 22,  1],\n",
              "        [ 0,  8, 16, 26, 29, 28, 21,  1],\n",
              "        [ 0,  9, 14, 26, 29, 28, 27,  1],\n",
              "        [ 0, 10, 16, 24, 29, 28, 19,  1],\n",
              "        [ 0, 11, 15, 26, 29, 28, 22,  1],\n",
              "        [ 0,  4, 13, 30, 29, 28, 27,  1],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0]],\n",
              "\n",
              "       [[ 0,  2, 15, 26, 29, 28, 19,  1],\n",
              "        [ 0,  3, 14, 31, 29, 28, 22,  1],\n",
              "        [ 7, 13, 31, 18, 29, 28, 22,  1],\n",
              "        [ 0,  8, 16, 26, 29, 28, 21,  1],\n",
              "        [ 0,  9, 14, 26, 29, 28, 27,  1],\n",
              "        [ 0, 10, 16, 24, 29, 28, 19,  1],\n",
              "        [ 0, 11, 15, 26, 29, 28, 22,  1],\n",
              "        [ 0,  4, 13, 30, 29, 28, 27,  1],\n",
              "        [ 5, 14, 31, 18, 29, 28, 21,  1],\n",
              "        [ 0,  6, 14, 26, 29, 28, 20,  1]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-8pFxiLZf8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "57680a42-1904-4d39-a03e-51c338037913"
      },
      "source": [
        "#This is what our queries look like after id imputation and padding\n",
        "queries_train[0:5]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17, 23, 15, 12],\n",
              "       [17, 23, 13, 12],\n",
              "       [17, 23, 13, 12],\n",
              "       [17, 23, 13, 12],\n",
              "       [17, 23, 16, 12]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewRjQQYIZ116",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "55f64914-aeb1-425d-ad67-cc7b5ee3a02f"
      },
      "source": [
        "#This is what our answers look like after id imputation and padding\n",
        "answers_train[0:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[19],\n",
              "       [22],\n",
              "       [22],\n",
              "       [27],\n",
              "       [19]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EePW5Z4aVDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c552017-124e-4195-cf93-338a04607724"
      },
      "source": [
        "print(story_maxlen)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9ni6xkhaX36",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8f8fd1f2-2d7b-4260-9182-6ae6ebf9160b"
      },
      "source": [
        "print(story_maxsents)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx0voaLmXGLc",
        "colab_type": "text"
      },
      "source": [
        "Now we are done with formatting our data in such a way that it has format similar to the one which we can feed to the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKdJiSPYviE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Dense, Embedding, Input, Lambda, Reshape, add, dot, Activation\n",
        "from keras.optimizers import Adam, RMSprop"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiLM3rqAYK2M",
        "colab_type": "text"
      },
      "source": [
        "Here we will not be using pretrained embeddings and we will allow the embedding\n",
        " learn so that it can catch the relation in story and the question to give the answer "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boRmfQS8b7qs",
        "colab_type": "text"
      },
      "source": [
        "Creating the embedding matrix for both story and the queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK_tXJvovaMB",
        "colab_type": "code",
        "outputId": "f8e0ed66-9da0-4c03-b85f-80dd5fc24d30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Embedding_dim = 40\n",
        "input_story = Input((story_maxsents, story_maxlen))\n",
        "embedded_story = Embedding(vocab_size, Embedding_dim)(input_story)\n",
        "embedded_story = Lambda(lambda x: K.sum(x, axis=2))(embedded_story)\n",
        "print(\"Shape of input stories,Shape of embedded stories\",input_story.shape,embedded_story.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of input stories,Shape of embedded stories (None, 10, 8) (None, 10, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWqU5Q0dvpd2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bbd0fca1-652d-41e0-dfe5-b166f57d64d1"
      },
      "source": [
        "input_question = Input((query_maxlen,))\n",
        "embedded_question = Embedding(vocab_size,Embedding_dim)(input_question)\n",
        "embedded_question = Lambda(lambda x: K.sum(x, axis=1))(embedded_question)\n",
        "embedded_question = Reshape((1, Embedding_dim))(embedded_question)\n",
        "print(\"Shape of input queries,Shape of embedded queries\",input_question.shape,embedded_story.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of input queries,Shape of embedded queries (None, 4) (None, 10, 40)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J52ED77WcvSw",
        "colab_type": "text"
      },
      "source": [
        "Our embedded stories will have a shape of (Vocab_size,max_sents,Embedding_dim)\n",
        "\n",
        "Our embedded queries will have a shape of (Vocab_size,1,Embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbNzp_m0v0DN",
        "colab_type": "code",
        "outputId": "882897cb-56ce-48d9-ddd2-2c25457382d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Getting the dot product of embedded story and the embedded query\n",
        "x = dot([embedded_story, embedded_question], 2)\n",
        "x.shape\n",
        "#What we gonna have will be a matrix of shape (10,1) for each story,question pair after their dot product"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, 10, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Q3ON0iGdh7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " #Flattening the vector\n",
        "x = Reshape((story_maxsents,))(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8hx1AsFeEqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4aa7c03e-db0a-454b-b361-de4b276487ab"
      },
      "source": [
        "x = Activation('softmax')(x)\n",
        "#Unflattening it again to be dotted later\n",
        "story_weights = Reshape((story_maxsents, 1))(x)\n",
        "print(\"story_weights.shape:\", story_weights.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "story_weights.shape: (None, 10, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehXmZyHyv2mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = dot([story_weights, embedded_story], 1)\n",
        "x = Reshape((Embedding_dim,))(x)\n",
        "ans = Dense(vocab_size, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8D8Z5AZv6IN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model([input_story, input_question], ans)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zou_kSNqv-dt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=RMSprop(lr=1e-2),loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK2SKaolwEKW",
        "colab_type": "code",
        "outputId": "ea50df0d-a6d2-40c5-e6b4-79eb91d29e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 811
        }
      },
      "source": [
        "# train the model\n",
        "ht = model.fit([inputs_train, queries_train],answers_train,epochs=20,batch_size=32,validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/20\n",
            "10000/10000 [==============================] - 1s 74us/step - loss: 0.4278 - accuracy: 0.8482 - val_loss: 0.0289 - val_accuracy: 0.9890\n",
            "Epoch 2/20\n",
            "10000/10000 [==============================] - 1s 58us/step - loss: 0.0232 - accuracy: 0.9931 - val_loss: 1.4917e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "10000/10000 [==============================] - 1s 58us/step - loss: 1.4475e-05 - accuracy: 1.0000 - val_loss: 1.0729e-09 - val_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "10000/10000 [==============================] - 1s 56us/step - loss: 1.5497e-10 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "10000/10000 [==============================] - 1s 59us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "10000/10000 [==============================] - 1s 59us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "10000/10000 [==============================] - 1s 55us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "10000/10000 [==============================] - 1s 53us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "10000/10000 [==============================] - 1s 56us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "10000/10000 [==============================] - 1s 54us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "10000/10000 [==============================] - 1s 55us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "10000/10000 [==============================] - 1s 53us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "10000/10000 [==============================] - 1s 54us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "10000/10000 [==============================] - 1s 54us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "10000/10000 [==============================] - 1s 54us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "10000/10000 [==============================] - 1s 55us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "10000/10000 [==============================] - 1s 53us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "10000/10000 [==============================] - 1s 57us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "10000/10000 [==============================] - 1s 59us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "10000/10000 [==============================] - 1s 55us/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgWXZM3vftFY",
        "colab_type": "text"
      },
      "source": [
        "Plotting the model curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj-nspQwfrUw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "67db167e-2159-4532-dc3c-f97d9e4cbba0"
      },
      "source": [
        "plt.plot(ht.history[\"loss\"],label = \"loss\")\n",
        "plt.plot(ht.history[\"val_loss\"],label = \"val_loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlwvU7V7gJQ0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "5a0fd792-0385-4444-d55a-b3f02ad3069a"
      },
      "source": [
        "plt.plot(ht.history[\"accuracy\"],label = \"accuracy\")\n",
        "plt.plot(ht.history[\"val_accuracy\"],label = \"val_accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Y1GrzHwufG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Checking how we weight each input sentence given a story and question\n",
        "debugging_model = Model([input_story, input_question], story_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niktGW-Twyji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Choosing a random story for all\n",
        "story_idx = np.random.choice(len(train_stories))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIQzEocMwz8c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Getting the weights from debug model\n",
        "i = inputs_train[story_idx:story_idx+1]\n",
        "q = queries_train[story_idx:story_idx+1]\n",
        "w = debugging_model.predict([i, q]).flatten()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kn7vgpdpw6Ix",
        "colab_type": "code",
        "outputId": "dec0307e-76c4-40bd-9a4c-48dd7e04c4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "story, question, ans = train_stories[story_idx]\n",
        "print(\"story is:\\n\")\n",
        "for i, line in enumerate(story):\n",
        "  print(\"{:1.10f}\".format(w[i]), \"\\t\", \" \".join(line))\n",
        "\n",
        "print(\"question:\", \" \".join(question))\n",
        "print(\"answer:\", ans)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "story is:\n",
            "\n",
            "0.0005270375 \t 0 John went back to the kitchen .\n",
            "0.0000000040 \t 1 Mary travelled to the garden .\n",
            "0.9994688630 \t 3 John journeyed to the hallway .\n",
            "0.0000041079 \t 4 Sandra moved to the bathroom .\n",
            "question: Where is John ?\n",
            "answer: hallway\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}